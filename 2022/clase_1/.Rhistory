knitr::opts_chunk$set(echo = TRUE)
library(tidymodels)
load('../2022/clase_2/data/EPH_2015_II.RData')
data$pp03i<-factor(data$pp03i, labels=c('1-SI', '2-No', '9-NS'))
data$intensi<-factor(data$intensi, labels=c('1-Sub_dem', '2-SO_no_dem',
'3-Ocup.pleno', '4-Sobreoc',
'5-No trabajo', '9-NS'))
data$pp07a<-factor(data$pp07a, labels=c('0-NC',
'1-Menos de un mes',
'2-1 a 3 meses',
'3-3 a 6 meses',
'4-6 a 12 meses',
'5-12 a 60 meses',
'6-MÃ¡s de 60 meses',
'9-NS'))
data <- data %>%
mutate(imp_inglab1=factor(imp_inglab1, labels=c('non_miss','miss')))
summary(data$imp_inglab1)
data <- data %>%
select(-p21)
data <- data %>%
select(-p21)
set.seed(123)
eph_split <- initial_split(data)
eph_train <- training(eph_split)
eph_test <- testing(eph_split)
eph_test <- testing(eph_split)
set.seed(234)
eph_cv <- vfold_cv(eph_train)
eph_cv
tree_spec <- decision_tree(
cost_complexity = tune(),
tree_depth = tune(),
min_n = tune()
) %>%
set_engine("rpart") %>%
set_mode("classification")
tree_spec
tree_grid <- grid_regular(cost_complexity(), tree_depth(), min_n(), levels = 4)
tree_grid
doParallel::registerDoParallel()
set.seed(345)
tree_rs <- tune_grid(
tree_spec,
imp_inglab1 ~ .,
resamples = eph_cv,
grid = tree_grid,
metrics = metric_set(precision, recall,
accuracy, f_meas)
)
tree_rs <- tune_grid(
tree_spec,
imp_inglab1 ~ .,
resamples = eph_cv,
grid = tree_grid,
metrics = metric_set(precision, recall,
accuracy, f_meas)
)
tree_rs
collect_metrics(tree_rs)
autoplot(tree_rs) + theme_light(base_family = "IBMPlexSans")
show_best(tree_rs, "f_meas")
best_model <- show_best(tree_rs, "f_meas")
final_tree <- finalize_model(tree_spec, best_model)
best_model
best_model <- select_best(tree_rs, "f_meas")
best_model
final_tree <- finalize_model(tree_spec, best_model)
final_tree
final_fit <- fit(final_tree, imp_inglab1 ~ ., eph_train)
final_fit
final_fit %>% translate()
final_fit
library(vip)
install.packages("vip")
library(vip)
final_fit %>%
vip(geom = "col", aesthetics = list(fill = "midnightblue", alpha = 0.8)) +
scale_y_continuous(expand = c(0, 0))
final_fit
final_fit %>%
vip(geom = "col", aesthetics = list(fill = "midnightblue", alpha = 0.8))
final_fit %>%
vip(geom = "col", aes = list(fill = "midnightblue", alpha = 0.8)) +
scale_y_continuous(expand = c(0, 0))
final_fit %>%
vip(geom = "col", aes (fill = "midnightblue", alpha = 0.8)) +
scale_y_continuous(expand = c(0, 0))
final_fit %>%
vip(geom = "col", aes = list(fill = "midnightblue", alpha = 0.8)) +
scale_y_continuous(expand = c(0, 0))
final_fit %>%
vip(geom = "col", aes = list(fill = "midnightblue", alpha = 0.8))
final_fit %>%
vip(geom = "col")
collect_metrics(final_fit)
eph_test %>%
predict(final_tree)
last_fit %>%
predict(final_tree)
valid_final <- last_fit(final_tree, imp_inglab1 ~ ., eph_split)
valid_final
collect_metrics(valid_final)
?collect_metrics
eph_split %>%
predict(final_fit)
eph_test %>%
predict(final_fit)
eph_test %>%
predict(valid_final)
eph_split %>%
predict(valid_final)
valid_final %>%
collect_predictions()
predictions <- valid_final %>%
collect_predictions()
predictions
preds %>%
metrics(imp_inglab1, .pred_class)
predictions %>%
metrics(imp_inglab1, .pred_class)
?metrics
predictions %>%
metric_set(imp_inglab1, .pred_class)
?metrics
final_tree %>%
predict(rphtest)
final_tree %>%
predict(rph_test)
final_fit %>%
predict(rph_test)
final_fit %>%
predict(eph_test)
final_fit %>%
predict(eph_test)
final_fit %>%
predict(eph_test) %>%
bind_rows(., eph_test)
final_fit %>%
predict(eph_test) %>%
bind_cols(., eph_test)
final_fit %>%
predict(eph_test) %>%
bind_cols(eph_test, .)
eph_test <- final_fit %>%
predict(eph_test) %>%
bind_cols(eph_test, .)
eph_test
class_metrics
```{# Multiple regression metrics}
```{# Multiple regression metrics}
eph_test
eph_test
eph_test
eph_test
eph_test
eph_test
```{# Multiple regression metrics}
eph_test <- final_fit %>%
predict(eph_test) %>%
bind_cols(eph_test, .)
hjk
```{# Multiple regression metrics}
```{# Multiple regression metrics}
hjk
eph_test <- final_fit %>%
predict(eph_test) %>%
bind_cols(eph_test, .)
class_metrics <- metric_set(precision, recall,
accuracy, f_meas)
class_metrics
# The returned function has arguments:
# fn(data, truth, estimate, na_rm = TRUE, ...)
class_metrics(truth = solubility, estimate = .pred_class)
# The returned function has arguments:
# fn(data, truth, estimate, na_rm = TRUE, ...)
class_metrics(eph_test, truth = imp_inglab1, estimate = .pred_class)
class_metrics <- metric_set(precision, recall,
accuracy, f_meas)
# The returned function has arguments:
# fn(data, truth, estimate, na_rm = TRUE, ...)
class_metrics(eph_test, truth = imp_inglab1, estimate = .pred_class)
eph_test
knitr::opts_chunk$set(echo = TRUE)
library(tidymodels)
# The returned function has arguments:
# fn(data, truth, estimate, na_rm = TRUE, ...)
class_metrics(eph_test, truth = imp_inglab1, estimate = .pred_class...27)
