---
title: "Clase 1 - Árboles de decisión"
author: "Diplomatura en Ciencias Sociales Computacionales"
date: '2023-03-03'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Árboles de decisión

## El problema

Segumos con nuestro problema central: predecir los ingresos de la ocupación principal (`p21`) en la EPH del segundo trimestre del 2015. Pero en esta oportunidad queremos evaluar si podemos predecir la no respuesta. Es decir, entrenar un modelo que nos permita predecir qué tan probable es que una persona NO responda ingresos.

Ya hemos preprocesado los datos y estamos listos

Lo primero que tenemos que hacer es importar las librerías con las que vamos a trabajar:

```{r message=FALSE, warning=FALSE}
library(tidymodels)
```

```{r}
load('../2022/clase_2/data/EPH_2015_II.RData')

data$pp03i<-factor(data$pp03i, labels=c('1-SI', '2-No', '9-NS'))

data$intensi<-factor(data$intensi, labels=c('1-Sub_dem', '2-SO_no_dem', 
                                            '3-Ocup.pleno', '4-Sobreoc',
                                            '5-No trabajo', '9-NS'))

data$pp07a<-factor(data$pp07a, labels=c('0-NC',
                                        '1-Menos de un mes',
                                        '2-1 a 3 meses',
                                        '3-3 a 6 meses',
                                        '4-6 a 12 meses',
                                        '5-12 a 60 meses',
                                        '6-Más de 60 meses',
                                        '9-NS'))


data <- data %>%
        mutate(imp_inglab1=factor(imp_inglab1, labels=c('non_miss','miss')))

summary(data$imp_inglab1)

```

Ahora, nuestra variable a predecir es el indicador `imp_inglab`. Por ende, eliminamos la $p21$.

```{r}
data <- data %>%
        select(-p21)
```

Lo primero que vamos a hacer es crear una partición de datos:

```{r}
set.seed(123)
eph_split <- initial_split(data)
eph_train <- training(eph_split)
eph_test <- testing(eph_split)
```

Y hacemos las muestras cross-validation:

```{r}
set.seed(234)
eph_cv <- vfold_cv(eph_train)
eph_cv
```

Ahora, armarmos la estructura del modelo pero con parámetros que queremos tunear. Por eso ponemos la función `tune()` en la definición de los distintos parámetros: el umbral de la métrica de pureza para definir la complejidad del árbol, la profundidad del árbol y el mínimo de variables que tiene que tener cada partición del nodo.

```{r}
tree_spec <- decision_tree(
  cost_complexity = tune(),
  tree_depth = tune(),
  min_n = tune()
) %>%
  set_engine("rpart") %>%
  set_mode("classification")

tree_spec
```

Con la función `grid_regular()` armamos una serie de combinaciones aleatorias posibles para los parámetros del modelo. Le decimos que nos de 4 niveles de valores posibles para cada uno de los parámetros, y que los combine.

```{r}
tree_grid <- grid_regular(cost_complexity(), tree_depth(), min_n(), levels = 4)

tree_grid
```

Ahora vamos a probar los posibles valores que puede adoptar el modelo con los distintos parámetros en las muestras con cross-validation.

```{r}
doParallel::registerDoParallel()

set.seed(345)
tree_rs <- tune_grid(
  tree_spec,
  imp_inglab1 ~ .,
  resamples = eph_cv,
  grid = tree_grid,
  metrics = metric_set(accuracy, kap)
)

tree_rs

```

```{r}
collect_metrics(tree_rs)
```

```{r}
autoplot(tree_rs) + theme_light(base_family = "IBMPlexSans")
```

```{r}
show_best(tree_rs, "accuracy")
select_best(tree_rs, "accuracy")
```
